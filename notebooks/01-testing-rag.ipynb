{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40ae4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell imports all the necessary libraries and adds the project's root \n",
    "# directory to the system path. This allows us to import our own modules, \n",
    "# like the `rag.py` and `settings.py` files we created earlier.\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pprint\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Add the project root to the Python path\n",
    "# This assumes the notebook is in a subdirectory of the project root.\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "    print(f\"Added '{project_root}' to the system path.\")\n",
    "\n",
    "# Now we can import our own modules\n",
    "from src.backend.core.rag import get_retriever\n",
    "from src.backend.core.settings import settings\n",
    "\n",
    "# LangChain specific imports\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8928e2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded. Testing with book: 'David Foster - Generative Deep Learning_ Teaching Machines To Paint, Write, Compose, and Play (2023, O'Reilly Media) - libgen.li'\n"
     ]
    }
   ],
   "source": [
    "# # 2. Configuration and Model Initialization\n",
    "#\n",
    "# Here we load our environment variables, define which book we want to test,\n",
    "# and initialize the LLM.\n",
    "\n",
    "# Load environment variables from the .env file in the project root\n",
    "load_dotenv() \n",
    "\n",
    "# -- IMPORTANT: Set this to the ID of the book you want to test --\n",
    "# The book_id is the filename of your PDF without the .pdf extension.\n",
    "# This should match one of the directories created by the ingestion script.\n",
    "BOOK_ID = \"David Foster - Generative Deep Learning_ Teaching Machines To Paint, Write, Compose, and Play (2023, O'Reilly Media) - libgen.li\"\n",
    "\n",
    "# Initialize the LLM from our settings\n",
    "llm = ChatGoogleGenerativeAI(model=settings.LLM_MODEL, temperature=0)\n",
    "\n",
    "print(f\"Configuration loaded. Testing with book: '{BOOK_ID}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bea97d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retriever loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# # 3. Load the Retriever\n",
    "#\n",
    "# We will now use the `get_retriever` function from our application's code.\n",
    "# This ensures we are testing the exact same logic that our final API will use.\n",
    "\n",
    "retriever = get_retriever(book_id=BOOK_ID)\n",
    "\n",
    "if retriever:\n",
    "    print(\"\\nRetriever loaded successfully!\")\n",
    "else:\n",
    "    print(\"\\nFailed to load retriever. Please check the BOOK_ID and ensure you have run the ingestion script.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ec18767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing retriever with query: 'implementation code of DCGAN.'\n",
      "\n",
      "Retrieved 4 documents:\n",
      "\n",
      "--- Document 1 ---\n",
      "Source: D:\\Programming\\Programming Tutor\\programming_tutor\\scripts\\..\\data\\David Foster - Generative Deep Learning_ Teaching Machines To Paint, Write, Compose, and Play (2023, O'Reilly Media) - libgen.li.pdf\n",
      "Page: 125\n",
      "Content: Networks. ”2 In this 2015 paper, the authors show how to build a deep convolutional\n",
      "GAN to generate realistic images from a variety of datasets. They also introduce sev‐\n",
      "eral changes that significantly improve the quality of the generated images.\n",
      "Running the Code for This Example\n",
      "The code for this example can be found in the Jupyter notebook\n",
      "located at notebooks/04_gan/01_dcgan/dcgan.ipynb in the book\n",
      "repository.\n",
      "The Bricks Dataset\n",
      "First, you’ll need to download the training data. We’ll be using the Images of LEGO\n",
      "Bricks dataset that is available through Kaggle. This is a computer-rendered collec‐\n",
      "tion of 40,000 photographic images of 50 different toy bricks, taken from multiple\n",
      "angles. Some example images of Brickki products are shown in Figure 4-3.\n",
      "Figure 4-3. Examples of images from the Bricks dataset\n",
      "Y ou can download the dataset by running the Kaggle dataset downloader script in the\n",
      "book repository, as shown in Example 4-1. This will save the images and accompany‐...\n",
      "\n",
      "--- Document 2 ---\n",
      "Source: D:\\Programming\\Programming Tutor\\programming_tutor\\scripts\\..\\data\\David Foster - Generative Deep Learning_ Teaching Machines To Paint, Write, Compose, and Play (2023, O'Reilly Media) - libgen.li.pdf\n",
      "Page: 133\n",
      "Content: Example 4-7. Compiling the DCGAN\n",
      "class DCGAN(models.Model):\n",
      "    def __init__(self, discriminator, generator, latent_dim):\n",
      "        super(DCGAN, self).__init__()\n",
      "        self.discriminator = discriminator\n",
      "        self.generator = generator\n",
      "        self.latent_dim = latent_dim\n",
      "    def compile(self, d_optimizer, g_optimizer):\n",
      "        super(DCGAN, self).compile()\n",
      "        self.loss_fn = losses.BinaryCrossentropy() \n",
      "        self.d_optimizer = d_optimizer\n",
      "        self.g_optimizer = g_optimizer\n",
      "        self.d_loss_metric = metrics.Mean(name=\"d_loss\")\n",
      "        self.g_loss_metric = metrics.Mean(name=\"g_loss\")\n",
      "    @property\n",
      "    def metrics(self):\n",
      "        return [self.d_loss_metric, self.g_loss_metric]\n",
      "    def train_step(self, real_images):\n",
      "        batch_size = tf.shape(real_images)[0]\n",
      "        random_latent_vectors = tf.random.normal(\n",
      "            shape=(batch_size, self.latent_dim)\n",
      "        ) \n",
      "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:...\n",
      "\n",
      "--- Document 3 ---\n",
      "Source: D:\\Programming\\Programming Tutor\\programming_tutor\\scripts\\..\\data\\David Foster - Generative Deep Learning_ Teaching Machines To Paint, Write, Compose, and Play (2023, O'Reilly Media) - libgen.li.pdf\n",
      "Page: 132\n",
      "Content: ing training\n",
      "Keras provides us with the ability to create a custom train_step function to imple‐\n",
      "ment this logic. Example 4-7 shows the full DCGAN model class.\n",
      "Deep Convolutional GAN (DCGAN) | 105...\n",
      "\n",
      "--- Document 4 ---\n",
      "Source: D:\\Programming\\Programming Tutor\\programming_tutor\\scripts\\..\\data\\David Foster - Generative Deep Learning_ Teaching Machines To Paint, Write, Compose, and Play (2023, O'Reilly Media) - libgen.li.pdf\n",
      "Page: 132\n",
      "Content: vector of ones, because we want to train the generator to produce images that the dis‐\n",
      "criminator thinks are real.\n",
      "Crucially, we must alternate the training of these two networks, making sure that we\n",
      "only update the weights of one network at a time. For example, during the generator\n",
      "training process, only the generator’s weights are updated. If we allowed the discrimi‐\n",
      "nator’s weights to change as well, the discriminator would just adjust so that it is more\n",
      "likely to predict the generated images to be real, which is not the desired outcome.\n",
      "We want generated images to be predicted close to 1 (real) because the generator is\n",
      "strong, not because the discriminator is weak.\n",
      "A diagram of the training process for the discriminator and generator is shown in\n",
      "Figure 4-5.\n",
      "Figure 4-5. Training the DCGAN—gray boxes indicate that the weights are frozen dur‐\n",
      "ing training\n",
      "Keras provides us with the ability to create a custom train_step function to imple‐...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # 4. Test 1: Document Retrieval\n",
    "#\n",
    "# Let's test the retriever by itself. We'll ask it a question and see what raw\n",
    "# documents (chunks) it pulls from the vector store. This helps verify that\n",
    "# the retrieval part of RAG is working correctly.\n",
    "\n",
    "query = \"implementation code of DCGAN.\"\n",
    "\n",
    "print(f\"Testing retriever with query: '{query}'\\n\")\n",
    "\n",
    "if retriever:\n",
    "    # .invoke() runs the retriever and gets the results\n",
    "    retrieved_docs = retriever.invoke(query)\n",
    "\n",
    "    print(f\"Retrieved {len(retrieved_docs)} documents:\\n\")\n",
    "    \n",
    "    # Use pprint for a cleaner print of the documents\n",
    "    for i, doc in enumerate(retrieved_docs):\n",
    "        print(f\"--- Document {i+1} ---\")\n",
    "        print(f\"Source: {doc.metadata.get('source', 'N/A')}\")\n",
    "        print(f\"Page: {doc.metadata.get('page', 'N/A')}\")\n",
    "        print(f\"Content: {doc.page_content[:]}...\\n\")\n",
    "else:\n",
    "    print(\"Retriever not available. Cannot perform test.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ace8ef57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG chain created. Ready to answer questions.\n"
     ]
    }
   ],
   "source": [
    "# # 5. Test 2: Full RAG Chain (End-to-End Test)\n",
    "#\n",
    "# Now, let's build and test the complete RAG chain. This chain will:\n",
    "# 1. Take a question.\n",
    "# 2. Use the retriever to fetch relevant documents.\n",
    "# 3. \"Stuff\" the documents and the question into a prompt.\n",
    "# 4. Pass the prompt to the LLM to generate a final answer.\n",
    "\n",
    "if retriever:\n",
    "    # Define the prompt template for the LLM\n",
    "    template = \"\"\"\n",
    "    You are an AI assistant for question-answering tasks.\n",
    "    Use the following pieces of retrieved context to answer the question.\n",
    "    If you don't know the answer, just say that you don't know.\n",
    "    Keep the answer concise and helpful.\n",
    "\n",
    "    Context:\n",
    "    {context}\n",
    "\n",
    "    Question:\n",
    "    {question}\n",
    "\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "    # This is the LangChain Expression Language (LCEL) way of building a chain\n",
    "    rag_chain = (\n",
    "        {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    print(\"RAG chain created. Ready to answer questions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37a7f6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asking the RAG chain: 'What are the components of a Generative Adversarial Network (GAN)?'\n",
      "\n",
      "--- Generated Answer ---\n",
      "A GAN consists of two networks: a generator and a discriminator.  The generator creates images, and the discriminator tries to distinguish between real and generated images.  The training process involves alternating training of these two networks.\n"
     ]
    }
   ],
   "source": [
    "# # Run the RAG Chain\n",
    "#\n",
    "# Now we can invoke the chain with our question and get the final answer.\n",
    "if 'rag_chain' in locals():\n",
    "    question_to_ask = \"What are the components of a Generative Adversarial Network (GAN)?\"\n",
    "    \n",
    "    print(f\"Asking the RAG chain: '{question_to_ask}'\\n\")\n",
    "    \n",
    "    # .invoke() on the chain runs the full process\n",
    "    final_answer = rag_chain.invoke(question_to_ask)\n",
    "    \n",
    "    print(\"--- Generated Answer ---\")\n",
    "    print(final_answer)\n",
    "else:\n",
    "    print(\"RAG chain not created. Cannot run this cell.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
